{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment is to classify given samples as positive or negative.\n",
    "Colon Tumor data contains 62 samples collected from colon-cancer patients. Among them, 40 tumor biopsies are from tumors (labelled as \"negative\") and 22 normal (labelled as \"positive\") biopsies are from healthy parts of the colons of the same patients. Two thousand out of around 6500 genes were selected based on the confidence in the measured expression levels.\n",
    "\n",
    "\n",
    "Two classifiers are used to do binary classification with different data specific variants\n",
    "\n",
    "1) Nearest Neighbour\n",
    "     a) with fixed K value\n",
    "     b) with variable K value\n",
    "     c) Class wise voting mechanism\n",
    "2) SVM with linear kernel\n",
    "\n",
    "For both the methods the preprocessing steps are same.\n",
    "Normailzation technique is as below :\n",
    "for every dimension among 2000 dimensions, \"minimum\" and \"maximum\" are found initially among 62 samples.\n",
    "then every value is normailzed with below formula\n",
    "\n",
    "f(x)=(x-min(dim_x))/(max(dim_x)-min(dim_x))\n",
    "\n",
    "The experiments are done in the following procedure.\n",
    "\n",
    "Step1 : Find the Minimum and maximum for each dimension among all 2000 dimensions\n",
    "\n",
    "Step2 : Normalize the data\n",
    "\n",
    "Step3 : Run classification\n",
    "\n",
    "\n",
    "\n",
    "Experiment 1 :\n",
    "Nearest Neighbour with class specific voting mechanism:\n",
    "\n",
    "Standard k nearest neighbour technique uses voting mechanism among the k values.\n",
    "But as our data is a bit biased i.e. positive class data size is 22 and negative class data size is 40, we are using a variant of voting mechanism for classification.\n",
    "In this method we will take top k samples from +ve class and calculate average distance.\n",
    "Again we will take top k samples from -ve class and claculate average distance.\n",
    "Then we will assign the lable which is of less distance.\n",
    "For all the sub experiments if the distance is same for +ve and -ve class then -ve class label is assigned as the number of -ve samples are more.(A prior belif)\n",
    "\n",
    "Experiment 1a:\n",
    "Here the K value is again class specific. i.e. we k value to take average is not same for both the classes.\n",
    "K value is choosen as 50% value for +ve class(count 22) and 20% value for -ve class(count 40).\n",
    "this heuristic is based on intution about the data.\n",
    "\n",
    "Experiment 1b:\n",
    "Here the K value is fixed to 5 for both the classes.\n",
    "\n",
    "Experiment 2 :\n",
    "Standard Nearest Neighbour:\n",
    "\n",
    "Standard k nearest neighbour technique uses voting mechanism among the k values.\n",
    "K value is fixed to 7.\n",
    "\n",
    "\n",
    "Experiment 3 :\n",
    "Here we use LibSVM along with linear Kerel. We can use polynomial or gaussian kernel. The data dimensions are high and number of samples are low we can work with Linear kernel itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with random K value : \n",
      "\n",
      "for 30.0% training data, accuracy is : 52.2727272727\n",
      "for 40.0% training data, accuracy is : 57.8947368421\n",
      "for 50.0% training data, accuracy is : 64.5161290323\n",
      "for 60.0% training data, accuracy is : 60.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "with fixed k value : \n",
      "\n",
      "for 30.0% training data, accuracy is : 63.6363636364\n",
      "for 40.0% training data, accuracy is : 52.6315789474\n",
      "for 50.0% training data, accuracy is : 61.2903225806\n",
      "for 60.0% training data, accuracy is : 60.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import  random\n",
    "\n",
    "min_array=np.zeros(2000);\n",
    "max_array=np.zeros(2000);\n",
    "\n",
    "pos_X=np.zeros([22,2000])\n",
    "neg_X=np.zeros([40,2000])\n",
    "\n",
    "pos_Y=np.zeros(22)\n",
    "neg_Y=np.ones(40)\n",
    "\n",
    "def findMinMax(ipath):\n",
    "    count=0\n",
    "    with open(ipath,'r') as fp:\n",
    "        for line in fp:\n",
    "            tokens=line.split(',')\n",
    "            if(count==0):\n",
    "                for i in range(0,2000):\n",
    "                    min_array[i]=float(tokens[i].replace('\\n',''));\n",
    "                    max_array[i]=float(tokens[i].replace('\\n',''));\n",
    "                count=count+1;\n",
    "            else:\n",
    "                for i in range(0,2000):\n",
    "                    cur_Val=float(tokens[i].replace('\\n',''))\n",
    "                    if(min_array[i]>cur_Val):min_array[i]=cur_Val;\n",
    "                    if(max_array[i]<cur_Val):max_array[i]=cur_Val;\n",
    "\n",
    "\n",
    "def prepareData2(ipath):\n",
    "    pos_co=0;\n",
    "    neg_co=0;\n",
    "    with open(ipath,'r') as fp:\n",
    "        for line in fp:\n",
    "            tokens=line.split(',');\n",
    "            tok2000=tokens[2000].strip().replace('\\n','');\n",
    "            if(tok2000=='positive'):\n",
    "                addToArray(pos_co,tokens,'pos')\n",
    "                pos_co=pos_co+1\n",
    "            else:\n",
    "                addToArray(neg_co,tokens,'neg')\n",
    "                neg_co=neg_co+1\n",
    "\n",
    "\n",
    "\n",
    "def addToArray(curr_line,tokens,val):\n",
    "    if(val=='pos'):\n",
    "     for i in range(0,2000):\n",
    "        cur_val=normalize(i,float(tokens[i].strip()))\n",
    "        pos_X[curr_line,i]=cur_val\n",
    "    else:\n",
    "     for i in range(0,2000):\n",
    "        cur_val=normalize(i,float(tokens[i].strip()))\n",
    "        neg_X[curr_line,i]=cur_val\n",
    "\n",
    "\n",
    "def normalize(i,value):\n",
    "    value=value-min_array[i];\n",
    "    value=value/(max_array[i]-min_array[i]);\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "def euclideanDistance(instance1, instance2):\n",
    "    distance = 0\n",
    "    dims=len(instance1)\n",
    "    for x in range(dims):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "\treturn math.sqrt(distance)\n",
    "\n",
    "\n",
    "\n",
    "#percent must be between 0 to 1\n",
    "def generateRandomInstances(percent):\n",
    "    pos_train_count=int(22*percent)\n",
    "    neg_train_count=int(40*percent)\n",
    "    rand_pos_train=random.sample(range(0,22),pos_train_count)\n",
    "    rand_neg_train=random.sample(range(0,40),neg_train_count)\n",
    "    rand_pos_test=(set(range(0,22))-set(rand_pos_train))\n",
    "    rand_neg_test=(set(range(0,40))-set(rand_neg_train))\n",
    "    return rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test\n",
    "\n",
    "\n",
    "def getNeighbors(trX,teX, k):\n",
    "\tdistances = []\n",
    "\tfor x in range(len(trX)):\n",
    "\t\tdist = euclideanDistance(teX, trX[x])\n",
    "\t\tdistances.append(dist)\n",
    "\tdistances.sort()\n",
    "\tneighbors = []\n",
    "\tfor x in range(k):\n",
    "\t\tneighbors.append(distances[x])\n",
    "\treturn neighbors\n",
    "\n",
    "def classify(rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test,percent,varKFlag):\n",
    "    if(varKFlag==1):pos_k,neg_k=calculateK(percent)\n",
    "    else:\n",
    "        pos_k=5\n",
    "        neg_k=5\n",
    "    pos_labels=[]\n",
    "    pos_test_samples=[pos_X[i] for i in rand_pos_test]\n",
    "    for pos_sample in pos_test_samples:\n",
    "        pos_neighbors=getNeighbors(pos_X[rand_pos_train],pos_sample,pos_k)\n",
    "        neg_neighbors=getNeighbors(neg_X[rand_neg_train],pos_sample,neg_k)\n",
    "        pos_labels.append(calcLabel(pos_neighbors,neg_neighbors))\n",
    "\n",
    "    neg_labels=[]\n",
    "    neg_test_samples=[neg_X[i] for i in rand_neg_test]\n",
    "    for neg_sample in neg_test_samples:\n",
    "        pos_neighbors=getNeighbors(pos_X[rand_pos_train],neg_sample,pos_k)\n",
    "        neg_neighbors=getNeighbors(neg_X[rand_neg_train],neg_sample,neg_k)\n",
    "        neg_labels.append(calcLabel(pos_neighbors,neg_neighbors))\n",
    "    return pos_labels,neg_labels\n",
    "\n",
    "\n",
    "\n",
    "def calcLabel(pos_neighbors,neg_neighbors):\n",
    "    pos_k=len(pos_neighbors)\n",
    "    neg_k=len(neg_neighbors)\n",
    "    pos_dist=0\n",
    "    neg_dist=0\n",
    "    for neighbor in pos_neighbors:\n",
    "        pos_dist+=neighbor\n",
    "    pos_dist=pos_dist/pos_k;\n",
    "    for neighbor in neg_neighbors:\n",
    "        neg_dist+=neighbor\n",
    "    neg_dist=neg_dist/neg_k;\n",
    "    if(pos_dist<neg_dist):\n",
    "        return 0\n",
    "    elif(pos_dist>neg_dist):\n",
    "        return 1\n",
    "    else: return 1 #prior belif\n",
    "\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif int(testSet[x]) is int(predictions[x]):\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def calculateK(percent):\n",
    "    pos_train_count=int(22*percent)\n",
    "    neg_train_count=int(40*percent)\n",
    "    pos_k=int(pos_train_count*0.5)\n",
    "    neg_k=int(neg_train_count*0.2)\n",
    "    return pos_k,neg_k\n",
    "\n",
    "\n",
    "def NN():\n",
    "    ipath='/home/kushwanth/ClassificationColonTumor/ColonTumor/colonTumor.data'\n",
    "    findMinMax(ipath);\n",
    "    prepareData2(ipath);\n",
    "    percents=[0.3,0.4,0.5,0.6]\n",
    "    print \"with random K value : \\n\"\n",
    "    #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    for percent in percents:\n",
    "        rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test=generateRandomInstances(percent)\n",
    "        pos_labels,neg_labels=classify(rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test,percent,1)\n",
    "        pos_labels=np.asarray(pos_labels)\n",
    "        neg_labels=np.asarray(neg_labels)\n",
    "        pred_labels=np.concatenate([pos_labels,neg_labels],axis=0)\n",
    "        curr_pos_y=np.zeros(len(rand_pos_test))\n",
    "        curr_neg_y=np.ones(len(rand_neg_test))\n",
    "        actual_labels=np.concatenate([curr_pos_y,curr_neg_y],axis=0)\n",
    "        print \"for \"+str(percent*100)+\"% training data, accuracy is : \" +str(getAccuracy(actual_labels,pred_labels))\n",
    "    print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    print \"with fixed k value : \\n\"\n",
    "    #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "    for percent in percents:\n",
    "        rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test=generateRandomInstances(percent)\n",
    "        pos_labels,neg_labels=classify(rand_pos_train,rand_neg_train,rand_pos_test,rand_neg_test,percent,0)\n",
    "        pos_labels=np.asarray(pos_labels)\n",
    "        neg_labels=np.asarray(neg_labels)\n",
    "        pred_labels=np.concatenate([pos_labels,neg_labels],axis=0)\n",
    "        curr_pos_y=np.zeros(len(rand_pos_test))\n",
    "        curr_neg_y=np.ones(len(rand_neg_test))\n",
    "        actual_labels=np.concatenate([curr_pos_y,curr_neg_y],axis=0)\n",
    "        print \"for \"+str(percent*100)+\"% training data, accuracy is : \" +str(getAccuracy(actual_labels,pred_labels))\n",
    "\n",
    "\n",
    "\n",
    "NN();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- linear: u'*v\n",
      "**********start***************\n",
      "training data percent : 30.0\n",
      "current # of training positive count 6\n",
      "current # of training negative count 12\n",
      "current # of test positive count 16\n",
      "current # of test negative count 28\n",
      "Accuracy = 86.3636% (38/44) (classification)\n",
      "=================================\n",
      "**********start***************\n",
      "training data percent : 40.0\n",
      "current # of training positive count 8\n",
      "current # of training negative count 16\n",
      "current # of test positive count 14\n",
      "current # of test negative count 24\n",
      "Accuracy = 92.1053% (35/38) (classification)\n",
      "=================================\n",
      "**********start***************\n",
      "training data percent : 50.0\n",
      "current # of training positive count 11\n",
      "current # of training negative count 20\n",
      "current # of test positive count 11\n",
      "current # of test negative count 20\n",
      "Accuracy = 83.871% (26/31) (classification)\n",
      "=================================\n",
      "**********start***************\n",
      "training data percent : 60.0\n",
      "current # of training positive count 13\n",
      "current # of training negative count 24\n",
      "current # of test positive count 9\n",
      "current # of test negative count 16\n",
      "Accuracy = 84% (21/25) (classification)\n",
      "=================================\n",
      "**********start***************\n",
      "training data percent : 70.0\n",
      "current # of training positive count 15\n",
      "current # of training negative count 28\n",
      "current # of test positive count 7\n",
      "current # of test negative count 12\n",
      "Accuracy = 73.6842% (14/19) (classification)\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "#this  file prepares the colon tumor data in libsvm format\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#read data line by line\n",
    "#lines in colontumor data is of format\n",
    "'''\n",
    " <feature1>,<feature2>,<feature3>.......,<feature2000>,<label>\n",
    "'''\n",
    "\n",
    "#required libsvm format\n",
    "'''\n",
    " Note 0 for positive 1 for negative\n",
    " <label> 1:<feature1> 2:<feature2> 3:<feature3>.......2000:<feature2000>\n",
    "'''\n",
    "\n",
    "'''\n",
    "Contains 62 samples collected from colon-cancer patients.\n",
    "Among them, 40 tumor biopsies are from tumors (labelled as \"negative\")\n",
    "and 22 normal (labelled as \"positive\") biopsies are from healthy parts of the colons of the same patients.\n",
    "Two thousand out of around 6500 genes were selected based on the confidence in the measured expression levels.\n",
    "\n",
    "we will divide 70:30 as train:test\n",
    "train\n",
    "40*0.7=28\n",
    "22*0.7=15\n",
    "\n",
    "test\n",
    "40-28=12\n",
    "22-15=7\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#ipath is input colon.data path\n",
    "#opath is folder where to store the train and test data\n",
    "#train_persent is persent of train range from 0.1 to 0.8 usually\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from svmutil import *\n",
    "\n",
    "\n",
    "min_array=np.zeros(2000);\n",
    "max_array=np.zeros(2000);\n",
    "\n",
    "\n",
    "def findMinMax(ipath):\n",
    "    count=0\n",
    "    with open(ipath,'r') as fp:\n",
    "        for line in fp:\n",
    "            tokens=line.split(',')\n",
    "            if(count==0):\n",
    "                for i in range(0,2000):\n",
    "                    min_array[i]=float(tokens[i]);\n",
    "                    max_array[i]=float(tokens[i]);\n",
    "                count=count+1;\n",
    "                continue;\n",
    "            for i in range(0,2000):\n",
    "                cur_Val=float(tokens[i])\n",
    "                if(min_array[i]>cur_Val):min_array[i]=cur_Val;\n",
    "                if(max_array[i]<cur_Val):max_array[i]=cur_Val;\n",
    "\n",
    "\n",
    "def prepareData(ipath,train_persent):\n",
    "    pos_count=0;\n",
    "    neg_count=0;\n",
    "    t_pos_count=int(22*train_persent);\n",
    "    print t_pos_count\n",
    "    t_neg_count=int(40*train_persent);\n",
    "    print t_neg_count\n",
    "    with open(ipath,'r') as fp:\n",
    "        for line in fp:\n",
    "            tokens=line.split(',');\n",
    "            '''\n",
    "            if(len(tokens)!=2001):\n",
    "                print count\n",
    "            '''\n",
    "            #print len(tokens)\n",
    "            curr_line=''\n",
    "            #print tokens[2000]\n",
    "            tok2000=tokens[2000].strip();\n",
    "            if(tok2000=='positive'):\n",
    "                curr_line='0';\n",
    "                pos_count=pos_count+1;\n",
    "                if(pos_count<=t_pos_count):\n",
    "                    path='/home/kushwanth/ClassificationColonTumor/train.data';\n",
    "                    addToFile(curr_line,path,tokens);\n",
    "                else:\n",
    "                    path='/home/kushwanth/ClassificationColonTumor/test.data';\n",
    "                    addToFile(curr_line,path,tokens);\n",
    "            else:\n",
    "                curr_line='1';\n",
    "                neg_count=neg_count+1;\n",
    "                if(neg_count<=t_neg_count):\n",
    "                    path='/home/kushwanth/ClassificationColonTumor/train.data';\n",
    "                    addToFile(curr_line,path,tokens);\n",
    "                else:\n",
    "                    path='/home/kushwanth/ClassificationColonTumor/test.data';\n",
    "                    addToFile(curr_line,path,tokens);\n",
    "\n",
    "\n",
    "\n",
    "def prepareData2(ipath,opath):\n",
    "    with open(ipath,'r') as fp:\n",
    "        for line in fp:\n",
    "            tokens=line.split(',');\n",
    "            tok2000=tokens[2000].strip();\n",
    "            if(tok2000=='positive'):\n",
    "                curr_line='0';\n",
    "                addToFile(curr_line,os.path.join(opath,'pos'),tokens)\n",
    "            else:\n",
    "                curr_line='1';\n",
    "                addToFile(curr_line,os.path.join(opath,'neg'),tokens)\n",
    "\n",
    "\n",
    "def addToFile(curr_line,path_new,tokens):\n",
    "    for i in range(0,2000):\n",
    "        j=i+1\n",
    "        cur_val=normalize(i,float(tokens[i].strip()))\n",
    "        curr_line=curr_line+' '+str(j)+':'+str(cur_val)\n",
    "    curr_line=curr_line+'\\n'\n",
    "    with open(path_new,'a') as ofp:\n",
    "        ofp.write(curr_line)\n",
    "\n",
    "def normalize(i,value):\n",
    "    value=value-min_array[i];\n",
    "    value=value/(max_array[i]-min_array[i]);\n",
    "    return value\n",
    "\n",
    "\n",
    "def runSVM(opath,kernal):\n",
    "    y_pos, x_pos = svm_read_problem(os.path.join(opath,'pos'));\n",
    "    y_neg, x_neg = svm_read_problem(os.path.join(opath,'neg'));\n",
    "    train_persent=0.3;\n",
    "    for i in range(1,6):\n",
    "        t_pos_count=int(22*train_persent);\n",
    "        t_neg_count=int(40*train_persent);\n",
    "        print \"**********start***************\"\n",
    "        print \"training data percent : \" +str(train_persent*100)\n",
    "        print \"current # of training positive count \"+str(len(y_pos[0:t_pos_count]))\n",
    "        print \"current # of training negative count \"+str(len(y_neg[0:t_neg_count]))\n",
    "        curr_train_y=y_pos[0:t_pos_count]+y_neg[0:t_neg_count];\n",
    "        curr_train_x=x_pos[0:t_pos_count]+x_neg[0:t_neg_count];\n",
    "        m = svm_train(curr_train_y,curr_train_x,kernal)\n",
    "        print \"current # of test positive count \"+str(len(y_pos[t_pos_count:len(y_pos)]))\n",
    "        print \"current # of test negative count \"+str(len(y_neg[t_neg_count:len(y_neg)]))\n",
    "        curr_test_y=y_pos[t_pos_count:len(y_pos)]+y_neg[t_neg_count:len(y_neg)];\n",
    "        curr_test_x=x_pos[t_pos_count:len(x_pos)]+x_neg[t_neg_count:len(x_neg)];\n",
    "        p_label, p_acc, p_val = svm_predict(curr_test_y,curr_test_x, m)\n",
    "        train_persent=train_persent+0.1\n",
    "        print \"=================================\"\n",
    "\n",
    "\n",
    "def cleanPrev():\n",
    "    cur_path=os.path.join(opath,'pos')\n",
    "    if(os.path.isfile(cur_path)):os.remove(cur_path)\n",
    "    cur_path=os.path.join(opath,'neg')\n",
    "    if(os.path.isfile(cur_path)):os.remove(cur_path)\n",
    "\n",
    "opath='/home/kushwanth/ClassificationColonTumor/libsvm_format'\n",
    "ipath='/home/kushwanth/ClassificationColonTumor/ColonTumor/colonTumor.data'\n",
    "findMinMax(ipath)\n",
    "#print min_array\n",
    "#print max_array\n",
    "cleanPrev()\n",
    "prepareData2(ipath,opath);\n",
    "print \"0 -- linear: u'*v\"\n",
    "kernal='-t 0'\n",
    "runSVM(opath,kernal);\n",
    "\n",
    "#prepareData(ipath,0.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
