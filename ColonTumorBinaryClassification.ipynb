{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment is to classify given samples as positive or negative.\n",
    "Colon Tumor data contains 62 samples collected from colon-cancer patients. Among them, 40 tumor biopsies are from tumors (labelled as \"negative\") and 22 normal (labelled as \"positive\") biopsies are from healthy parts of the colons of the same patients. Two thousand out of around 6500 genes were selected based on the confidence in the measured expression levels.\n",
    "\n",
    "\n",
    "Two classifiers are used to do binary classification with different data specific variants\n",
    "\n",
    "1) Nearest Neighbour\n",
    "     a) with fixed K value\n",
    "     b) with variable K value\n",
    "     c) Class wise voting mechanism\n",
    "2) SVM with linear kernel\n",
    "\n",
    "For both the methods the preprocessing steps are same.\n",
    "Normailzation technique is as below :\n",
    "for every dimension among 2000 dimensions, \"minimum\" and \"maximum\" are found initially among 62 samples.\n",
    "then every value is normailzed with below formula\n",
    "\n",
    "f(x)=(x-min(dim_x))/(max(dim_x)-min(dim_x))\n",
    "\n",
    "The experiments are done in the following procedure.\n",
    "\n",
    "Step1 : Find the Minimum and maximum for each dimension among all 2000 dimensions\n",
    "\n",
    "Step2 : Normalize the data\n",
    "\n",
    "Step3 : Run classification\n",
    "\n",
    "\n",
    "\n",
    "Experiment 1 :\n",
    "Nearest Neighbour with class specific voting mechanism:\n",
    "\n",
    "Standard k nearest neighbour technique uses voting mechanism among the k values.\n",
    "But as our data is a bit biased i.e. positive class data size is 22 and negative class data size is 40, we are using a variant of voting mechanism for classification.\n",
    "In this method we will take top k samples from +ve class and calculate average distance.\n",
    "Again we will take top k samples from -ve class and claculate average distance.\n",
    "Then we will assign the lable which is of less distance.\n",
    "For all the sub experiments if the distance is same for +ve and -ve class then -ve class label is assigned as the number of -ve samples are more.(A prior belif)\n",
    "\n",
    "Experiment 1a:\n",
    "Here the K value is again class specific. i.e. we k value to take average is not same for both the classes.\n",
    "K value is choosen as 50% value for +ve class(count 22) and 20% value for -ve class(count 40).\n",
    "this heuristic is based on intution about the data.\n",
    "\n",
    "Experiment 1b:\n",
    "Here the K value is fixed to 5 for both the classes.\n",
    "\n",
    "Experiment 2 :\n",
    "Standard Nearest Neighbour:\n",
    "\n",
    "Standard k nearest neighbour technique uses voting mechanism among the k values.\n",
    "K value is fixed to 7.\n",
    "\n",
    "\n",
    "Experiment 3 :\n",
    "Here we use LibSVM along with linear Kerel. We can use polynomial or gaussian kernel. The data dimensions are high and number of samples are low we can work with Linear kernel itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
